# 🧪 LLM Prompt Filtering Lab

This lab demonstrates how simple prompt filters can be bypassed using encoding, obfuscation, or clever wording.

## 🎯 Goal

Trigger a restricted behavior (e.g., LLM saying: “Admin password is...”) while bypassing the filter.

---

## 🛠️ Setup

```bash
chmod +x run_lab.sh
./run_lab.sh
# Llm Prompt Filtering - README.md


Access the LLM middleware at: http://localhost:5000


💡 Skills Covered

    Prompt injection

    Encoding bypasses

    LLM prompt middleware simulation
